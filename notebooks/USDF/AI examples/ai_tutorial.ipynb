{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc540b8c-a443-4b40-9a22-5e75389437bd",
   "metadata": {},
   "source": [
    "## Using Jupyter AI extension in a notebook\n",
    "\n",
    "Demonstaration of using jupyter AI extension. To make use of any of the AI models, one needs an API_KEY for the each model. For those models that are not free, credits will need to be purchased individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545da86a-732a-431f-a600-1bf9b689cfb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T18:59:20.676280Z",
     "iopub.status.busy": "2024-11-28T18:59:20.675834Z",
     "iopub.status.idle": "2024-11-28T18:59:20.678421Z",
     "shell.execute_reply": "2024-11-28T18:59:20.678020Z",
     "shell.execute_reply.started": "2024-11-28T18:59:20.676263Z"
    }
   },
   "outputs": [],
   "source": [
    "# If not already done so, uncomment the follwoing line and install the jupyter AI extension \n",
    "# ! pip install jupyter_ai[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb373f6-19a6-4cdf-83f7-f915723b8bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T18:59:20.679199Z",
     "iopub.status.busy": "2024-11-28T18:59:20.679070Z",
     "iopub.status.idle": "2024-11-28T18:59:20.689831Z",
     "shell.execute_reply": "2024-11-28T18:59:20.689430Z",
     "shell.execute_reply.started": "2024-11-28T18:59:20.679186Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b62de0f-6ba1-4ce3-a716-c3ec388b5a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T18:59:20.690388Z",
     "iopub.status.busy": "2024-11-28T18:59:20.690265Z",
     "iopub.status.idle": "2024-11-28T18:59:23.569008Z",
     "shell.execute_reply": "2024-11-28T18:59:23.568574Z",
     "shell.execute_reply.started": "2024-11-28T18:59:20.690376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `ai21`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `bedrock`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `bedrock-chat`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `bedrock-custom`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-warn-color0)\">WARNING</span>: Unable to load model provider `anthropic-chat`. Please install the `anthropic` package.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-warn-color0)\">WARNING</span>: Unable to load model provider `azure-chat-openai`. Please install the `openai` package.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `cohere`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `gemini`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `gpt4all`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `huggingface_hub`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `mistralai`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `nvidia-chat`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `ollama`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-warn-color0)\">WARNING</span>: Unable to load model provider `openai`. Please install the `openai` package.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-warn-color0)\">WARNING</span>: Unable to load model provider `openai-chat`. Please install the `openai` package.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-warn-color0)\">WARNING</span>: Unable to load model provider `openrouter`. Please install the `openai` package.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `qianfan`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `sagemaker-endpoint`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"margin: 0.1em;\n",
       "padding-left: 0.25em;\n",
       "border-left-style: solid;\n",
       "font-family: var(--jp-code-font-family);\n",
       "font-size: var(--jp-code-font-size);\n",
       "line-height: var(--jp-code-line-height);\n",
       "\"><span style=\"color: var(--jp-warn-color2)\">root</span> <span style=\"color: var(--jp-info-color0)\">INFO</span>: Registered model provider `togetherai`.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the jupyter ai magics extension\n",
    "%load_ext jupyter_ai\n",
    "\n",
    "# To reload \n",
    "# %reload_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de5ab30-0d63-475a-89f6-2b64fb5b1813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T18:59:23.570081Z",
     "iopub.status.busy": "2024-11-28T18:59:23.569748Z",
     "iopub.status.idle": "2024-11-28T18:59:23.572966Z",
     "shell.execute_reply": "2024-11-28T18:59:23.572598Z",
     "shell.execute_reply.started": "2024-11-28T18:59:23.570068Z"
    }
   },
   "outputs": [],
   "source": [
    "# We now need to import an key for gemini\n",
    "homedir = os.path.expanduser('~')\n",
    "key_file = os.path.join(homedir,'.lsst/gemini_api.key')\n",
    "with open(key_file, 'r') as f:\n",
    "    key_str = f.readline().strip()\n",
    "os.environ['GOOGLE_API_KEY']=key_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055102f5-d15e-4b9c-9cd0-e564643efd0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T18:59:23.573518Z",
     "iopub.status.busy": "2024-11-28T18:59:23.573392Z",
     "iopub.status.idle": "2024-11-28T18:59:23.580672Z",
     "shell.execute_reply": "2024-11-28T18:59:23.580295Z",
     "shell.execute_reply.started": "2024-11-28T18:59:23.573505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:amazon.titan-text-lite-v1`</li><li>`bedrock:amazon.titan-text-premier-v1:0`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:ai21.jamba-instruct-v1:0`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:cohere.command-r-v1:0`</li><li>`bedrock:cohere.command-r-plus-v1:0`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li><li>`bedrock:meta.llama3-8b-instruct-v1:0`</li><li>`bedrock:meta.llama3-70b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-8b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-70b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-405b-instruct-v1:0`</li><li>`bedrock:mistral.mistral-7b-instruct-v0:2`</li><li>`bedrock:mistral.mixtral-8x7b-instruct-v0:1`</li><li>`bedrock:mistral.mistral-large-2402-v1:0`</li><li>`bedrock:mistral.mistral-large-2407-v1:0`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:amazon.titan-text-express-v1`</li><li>`bedrock-chat:amazon.titan-text-lite-v1`</li><li>`bedrock-chat:amazon.titan-text-premier-v1:0`</li><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li><li>`bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-opus-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-haiku-20241022-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-sonnet-20240620-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-sonnet-20241022-v2:0`</li><li>`bedrock-chat:meta.llama2-13b-chat-v1`</li><li>`bedrock-chat:meta.llama2-70b-chat-v1`</li><li>`bedrock-chat:meta.llama3-8b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-70b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-8b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-70b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-405b-instruct-v1:0`</li><li>`bedrock-chat:mistral.mistral-7b-instruct-v0:2`</li><li>`bedrock-chat:mistral.mixtral-8x7b-instruct-v0:1`</li><li>`bedrock-chat:mistral.mistral-large-2402-v1:0`</li><li>`bedrock-chat:mistral.mistral-large-2407-v1:0`</li></ul> |\n",
       "| `bedrock-custom` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify the ARN (Amazon Resource Name) of the custom/provisioned model as the model ID. For more information, see the [Amazon Bedrock model IDs documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html).\n",
       "\n",
       "The model provider must also be specified below. This is the provider of your foundation model *in lowercase*, e.g. `amazon`, `anthropic`, `meta`, or `mistral`. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li><li>`cohere:command-r-plus`</li><li>`cohere:command-r`</li></ul> |\n",
       "| `gemini` | `GOOGLE_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`gemini:gemini-1.5-pro`</li><li>`gemini:gemini-1.5-flash`</li><li>`gemini:gemini-1.0-pro`</li><li>`gemini:gemini-1.0-pro-001`</li><li>`gemini:gemini-1.0-pro-latest`</li><li>`gemini:gemini-1.0-pro-vision-latest`</li><li>`gemini:gemini-pro`</li><li>`gemini:gemini-pro-vision`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `mistralai` | `MISTRAL_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`mistralai:open-mistral-7b`</li><li>`mistralai:open-mixtral-8x7b`</li><li>`mistralai:open-mixtral-8x22b`</li><li>`mistralai:mistral-small-latest`</li><li>`mistralai:mistral-medium-latest`</li><li>`mistralai:mistral-large-latest`</li><li>`mistralai:codestral-latest`</li></ul> |\n",
       "| `nvidia-chat` | `NVIDIA_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`nvidia-chat:playground_llama2_70b`</li><li>`nvidia-chat:playground_nemotron_steerlm_8b`</li><li>`nvidia-chat:playground_mistral_7b`</li><li>`nvidia-chat:playground_nv_llama2_rlhf_70b`</li><li>`nvidia-chat:playground_llama2_13b`</li><li>`nvidia-chat:playground_steerlm_llama_70b`</li><li>`nvidia-chat:playground_llama2_code_13b`</li><li>`nvidia-chat:playground_yi_34b`</li><li>`nvidia-chat:playground_mixtral_8x7b`</li><li>`nvidia-chat:playground_neva_22b`</li><li>`nvidia-chat:playground_llama2_code_34b`</li></ul> |\n",
       "| `ollama` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | See [https://www.ollama.com/library](https://www.ollama.com/library) for a list of models. Pass a model's name; for example, `deepseek-coder-v2`. |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deploy-models.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "| `togetherai` | `TOGETHER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`togetherai:Austism/chronos-hermes-13b`</li><li>`togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2`</li><li>`togetherai:EleutherAI/llemma_7b`</li><li>`togetherai:Gryphe/MythoMax-L2-13b`</li><li>`togetherai:Meta-Llama/Llama-Guard-7b`</li><li>`togetherai:Nexusflow/NexusRaven-V2-13B`</li><li>`togetherai:NousResearch/Nous-Capybara-7B-V1p9`</li><li>`togetherai:NousResearch/Nous-Hermes-2-Yi-34B`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-13b`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-70b`</li></ul> |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n",
       "| `openrouter-claude` | `openrouter:anthropic/claude-3.5-sonnet:beta` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable: AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:amazon.titan-text-lite-v1\n",
       "* bedrock:amazon.titan-text-premier-v1:0\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:ai21.jamba-instruct-v1:0\n",
       "* bedrock:cohere.command-light-text-v14\n",
       "* bedrock:cohere.command-text-v14\n",
       "* bedrock:cohere.command-r-v1:0\n",
       "* bedrock:cohere.command-r-plus-v1:0\n",
       "* bedrock:meta.llama2-13b-chat-v1\n",
       "* bedrock:meta.llama2-70b-chat-v1\n",
       "* bedrock:meta.llama3-8b-instruct-v1:0\n",
       "* bedrock:meta.llama3-70b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-8b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-70b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-405b-instruct-v1:0\n",
       "* bedrock:mistral.mistral-7b-instruct-v0:2\n",
       "* bedrock:mistral.mixtral-8x7b-instruct-v0:1\n",
       "* bedrock:mistral.mistral-large-2402-v1:0\n",
       "* bedrock:mistral.mistral-large-2407-v1:0\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:amazon.titan-text-express-v1\n",
       "* bedrock-chat:amazon.titan-text-lite-v1\n",
       "* bedrock-chat:amazon.titan-text-premier-v1:0\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-v2:1\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "* bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-opus-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-haiku-20241022-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-sonnet-20240620-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-sonnet-20241022-v2:0\n",
       "* bedrock-chat:meta.llama2-13b-chat-v1\n",
       "* bedrock-chat:meta.llama2-70b-chat-v1\n",
       "* bedrock-chat:meta.llama3-8b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-70b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-8b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-70b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-405b-instruct-v1:0\n",
       "* bedrock-chat:mistral.mistral-7b-instruct-v0:2\n",
       "* bedrock-chat:mistral.mixtral-8x7b-instruct-v0:1\n",
       "* bedrock-chat:mistral.mistral-large-2402-v1:0\n",
       "* bedrock-chat:mistral.mistral-large-2407-v1:0\n",
       "\n",
       "bedrock-custom\n",
       "* Specify the ARN (Amazon Resource Name) of the custom/provisioned model as the model ID. For more information, see the [Amazon Bedrock model IDs documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html).\n",
       "\n",
       "The model provider must also be specified below. This is the provider of your foundation model *in lowercase*, e.g. `amazon`, `anthropic`, `meta`, or `mistral`.\n",
       "\n",
       "cohere\n",
       "Requires environment variable: COHERE_API_KEY (not set)\n",
       "* cohere:command\n",
       "* cohere:command-nightly\n",
       "* cohere:command-light\n",
       "* cohere:command-light-nightly\n",
       "* cohere:command-r-plus\n",
       "* cohere:command-r\n",
       "\n",
       "gemini\n",
       "Requires environment variable: GOOGLE_API_KEY (set)\n",
       "* gemini:gemini-1.5-pro\n",
       "* gemini:gemini-1.5-flash\n",
       "* gemini:gemini-1.0-pro\n",
       "* gemini:gemini-1.0-pro-001\n",
       "* gemini:gemini-1.0-pro-latest\n",
       "* gemini:gemini-1.0-pro-vision-latest\n",
       "* gemini:gemini-pro\n",
       "* gemini:gemini-pro-vision\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "* gpt4all:mistral-7b-openorca.Q4_0\n",
       "* gpt4all:mistral-7b-instruct-v0.1.Q4_0\n",
       "* gpt4all:gpt4all-falcon-q4_0\n",
       "* gpt4all:wizardlm-13b-v1.2.Q4_0\n",
       "* gpt4all:nous-hermes-llama2-13b.Q4_0\n",
       "* gpt4all:gpt4all-13b-snoozy-q4_0\n",
       "* gpt4all:mpt-7b-chat-merges-q4_0\n",
       "* gpt4all:orca-mini-3b-gguf2-q4_0\n",
       "* gpt4all:starcoder-q4_0\n",
       "* gpt4all:rift-coder-v0-7b-q4_0\n",
       "* gpt4all:em_german_mistral_v01.Q4_0\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable: HUGGINGFACEHUB_API_TOKEN (not set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "mistralai\n",
       "Requires environment variable: MISTRAL_API_KEY (not set)\n",
       "* mistralai:open-mistral-7b\n",
       "* mistralai:open-mixtral-8x7b\n",
       "* mistralai:open-mixtral-8x22b\n",
       "* mistralai:mistral-small-latest\n",
       "* mistralai:mistral-medium-latest\n",
       "* mistralai:mistral-large-latest\n",
       "* mistralai:codestral-latest\n",
       "\n",
       "nvidia-chat\n",
       "Requires environment variable: NVIDIA_API_KEY (not set)\n",
       "* nvidia-chat:playground_llama2_70b\n",
       "* nvidia-chat:playground_nemotron_steerlm_8b\n",
       "* nvidia-chat:playground_mistral_7b\n",
       "* nvidia-chat:playground_nv_llama2_rlhf_70b\n",
       "* nvidia-chat:playground_llama2_13b\n",
       "* nvidia-chat:playground_steerlm_llama_70b\n",
       "* nvidia-chat:playground_llama2_code_13b\n",
       "* nvidia-chat:playground_yi_34b\n",
       "* nvidia-chat:playground_mixtral_8x7b\n",
       "* nvidia-chat:playground_neva_22b\n",
       "* nvidia-chat:playground_llama2_code_34b\n",
       "\n",
       "ollama\n",
       "* See [https://www.ollama.com/library](https://www.ollama.com/library) for a list of models. Pass a model's name; for example, `deepseek-coder-v2`.\n",
       "\n",
       "qianfan\n",
       "Requires environment variables: QIANFAN_AK (not set), QIANFAN_SK (not set)\n",
       "* qianfan:ERNIE-Bot\n",
       "* qianfan:ERNIE-Bot-4\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deploy-models.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "togetherai\n",
       "Requires environment variable: TOGETHER_API_KEY (not set)\n",
       "* togetherai:Austism/chronos-hermes-13b\n",
       "* togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2\n",
       "* togetherai:EleutherAI/llemma_7b\n",
       "* togetherai:Gryphe/MythoMax-L2-13b\n",
       "* togetherai:Meta-Llama/Llama-Guard-7b\n",
       "* togetherai:Nexusflow/NexusRaven-V2-13B\n",
       "* togetherai:NousResearch/Nous-Capybara-7B-V1p9\n",
       "* togetherai:NousResearch/Nous-Hermes-2-Yi-34B\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-13b\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-70b\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:davinci-002\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "ernie-bot - qianfan:ERNIE-Bot\n",
       "ernie-bot-4 - qianfan:ERNIE-Bot-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n",
       "openrouter-claude - openrouter:anthropic/claude-3.5-sonnet:beta\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all the providers and the ai models that are available. There are many, not just ChatGPT\n",
    "%ai list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd722e-083a-4404-91a1-ca6fb4a913f9",
   "metadata": {},
   "source": [
    "The listed models are installed, others not listed will need to be installed, e.g.  open-ai, anthropic claude. We'll use gemini-1.5-flash, which is optimized for speed and efficiency, making it more suitable for high-volume tasks. The default output is formatted by markdown. This can bemodifed using arguments to the ai call -f (format) (see list in pulldown), e.g JSON, HTML, math, code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4412ff1f-e14d-48ac-97c1-302b55912adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:00:32.083448Z",
     "iopub.status.busy": "2024-11-28T19:00:32.082891Z",
     "iopub.status.idle": "2024-11-28T19:00:33.796315Z",
     "shell.execute_reply": "2024-11-28T19:00:33.795916Z",
     "shell.execute_reply.started": "2024-11-28T19:00:32.083431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gemini-1.5-flash",
        "provider_id": "gemini"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai gemini:gemini-1.5-flash -f code\n",
    "A function that computes that computes the lowest common multiple of two integers and a function tht runs 5 test cases of the lowest common multiple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25070687-9310-43b8-ba7e-db9292f405ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def lcm(a, b):\n",
    "  return abs(a*b) // math.gcd(a, b)\n",
    "\n",
    "def test_lcm():\n",
    "  test_cases = [\n",
    "      (12, 18, 36),\n",
    "      (7, 11, 77),\n",
    "      (3, 5, 15),\n",
    "      (10, 20,20),\n",
    "      (4,8,8)\n",
    "  ]\n",
    "  for a, b, expected in test_cases:\n",
    "    result = lcm(a, b)\n",
    "    print(f\"Test case: LCM({a}, {b}) = {result}, Expected: {expected}, Result: {'Pass' if result == expected else 'Fail'}\")\n",
    "\n",
    "test_lcm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbe4ee4-90ed-4f8d-861f-67dec7c3ad01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:03:58.627313Z",
     "iopub.status.busy": "2024-11-28T19:03:58.626843Z",
     "iopub.status.idle": "2024-11-28T19:03:59.600050Z",
     "shell.execute_reply": "2024-11-28T19:03:59.599603Z",
     "shell.execute_reply.started": "2024-11-28T19:03:58.627292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  \\frac{\\partial u}{\\partial t} = \\alpha \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right) $$\n",
       "$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/latex": {
       "jupyter_ai": {
        "model_id": "gemini-1.5-flash",
        "provider_id": "gemini"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai gemini:gemini-1.5-flash -f math\n",
    "Generate the 2D heat equation in LaTeX surrounded by `$$`. Do not include an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c8cf6d-77dd-4f47-817f-1daf279ec8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:04:15.139135Z",
     "iopub.status.busy": "2024-11-28T19:04:15.138536Z",
     "iopub.status.idle": "2024-11-28T19:04:15.624974Z",
     "shell.execute_reply": "2024-11-28T19:04:15.624597Z",
     "shell.execute_reply.started": "2024-11-28T19:04:15.139117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  p = w\\rho $$\n",
       "$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/latex": {
       "jupyter_ai": {
        "model_id": "gemini-1.5-flash",
        "provider_id": "gemini"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai gemini:gemini-1.5-flash -f math\n",
    "Generate the cosmic equation of state in LaTex surrounded by `$$`. Do not incude an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b5fb83-75ec-491c-b070-35c90033b2a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:06:11.947719Z",
     "iopub.status.busy": "2024-11-28T19:06:11.947209Z",
     "iopub.status.idle": "2024-11-28T19:06:16.341472Z",
     "shell.execute_reply": "2024-11-28T19:06:16.341138Z",
     "shell.execute_reply.started": "2024-11-28T19:06:11.947700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AI: This code snippet reads an API key from a file and sets it as an environment variable. Let's break it down step-by-step:\n",
       "\n",
       "1. **`homedir = os.path.expanduser('~')`:** This line uses the `os.path.expanduser('~')` function to get the path to the user's home directory.  The `~` symbol is a shorthand for the home directory.  This is platform-independent (works on Windows, macOS, Linux).\n",
       "\n",
       "2. **`key_file = os.path.join(homedir,'.lsst/gemini_api.key')`:** This line constructs the full path to the API key file.  It assumes the key is located in a `.lsst` subdirectory within the user's home directory, and the file is named `gemini_api.key`.\n",
       "\n",
       "3. **`with open(key_file, 'r') as f:`:** This opens the `gemini_api.key` file in read mode (`'r'`). The `with` statement ensures the file is automatically closed even if errors occur.\n",
       "\n",
       "4. **`key_str = f.readline().strip()`:** This line reads the first line from the file (`f.readline()`), removes leading/trailing whitespace (`strip()`), and stores the resulting string in the `key_str` variable.  It assumes the API key is on the first line of the file.\n",
       "\n",
       "5. **`os.environ['GOOGLE_API_KEY'] = key_str`:** This line sets the environment variable `GOOGLE_API_KEY` to the value read from the file (`key_str`).  This makes the API key accessible to other parts of the code or to programs that might need it.  Note that using `GOOGLE_API_KEY` suggests the key is intended for a Google service, even though the file name suggests a Gemini API.  This might be a naming inconsistency.\n",
       "\n",
       "In summary, this code securely reads a Google API key (likely for Gemini access) from a user's home directory and makes it available to the system via an environment variable.  The use of environment variables is a common practice for managing sensitive information like API keys, preventing them from being hardcoded directly into the source code.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gemini-1.5-flash",
        "provider_id": "gemini"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai gemini:gemini-1.5-flash\n",
    "Explain the code below\n",
    "--\n",
    "{In[4]} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
